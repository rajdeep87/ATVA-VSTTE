\section{Experimental Results}

We have implemented ACDLP for bounded safety verification of C programs.  
ACDLP is implemented in C++ on top of the
\textsc{CPROVER}~\cite{cprover} framework as an extension of 2LS~\cite{2ls}
and consists of around 9~KLOC. 
The template polyhedra domain is implemented in C++ in 10~KLOC.  Templates
can be intervals, octagons, zones, equalities, or restricted polyhedra.  Our
domain handles all C operators, including bit-wise ones, and supports
precise complementation of meet irreducibles, which is necessary for
conflict-driven learning.  Our tool and benchmarks are available 
at~\url{http://www.cprover.org/acdcl/}.

We verified a total of~85 ANSI-C benchmarks.  These are derived from:
(1)~the bit-vector regression category in SV-COMP'16; (2)~ANSI-C models of
hardware circuits auto-generated by v2c~\cite{mtk2016} from VIS Verilog
models and opencores.org; (3)~controller code with varying loop bounds 
auto-generated from Simulink model and control 
intensive programs with nested loops containing relational properties. 
%The software models drawn from hardware benchmarks contains complex bit-wise
%operations, which are handled out-of-the-box by our domain implementation. 
All the programs with bounded loops are completely unrolled before
analysis.  

We~compare ACDLP with the state-of-the-art SAT-based bounded model checker
CBMC (\cite{cbmc}, version 5.5) and a commercial static analysis tool,
Astr{\'e}e (\cite{astree}, version 14.10).  CBMC uses MiniSAT~2.2.1 in the
backend.  Astr{\'e}e uses a range of abstract domains, which includes
interval, bit-field, congruence, trace partitioning, and relational domains
(octagons, polyhedra, zones, equalities, filter).  To enable fair comparison
using Astr{\'e}e, all bounded loops in the program are completely unwound up
to a given bound before passing to Astr{\'e}e.  This prevents Astr{\'e}e
from widening loops.
%
ACDLP is instantiated to a product of the Booleans and the Interval or
Octagon domain.  ACDLP is also configured with a decision heuristic 
(ordered, random, activity-based), propagation (forward, backward and multi-way), 
and conflict-analysis (learning UIP, DPLL-style).  The timeout for our
experiments is set to~200 seconds.
%
\Omit {
To enable precise analysis using Astr{\'e}e, all our benchmarks are 
manually instrumented with partition directives which provides external 
hint to the tool to guide the trace partitioning heuristics.  Usually, 
such high-precision is not needed for static analysis, since it makes 
the analysis very expensive.  Without trace partitioning, the 
analysis using Astr{\'e}e shows high degree of imprecision. 
}

\input{graph1}
\input{plot-runtimes}
%

\medskip

\noindent \textbf{ACDLP versus CBMC}
Fig.~\ref{fig:results} presents a comparison between CBMC
and ACDLP.  Fig.~\ref{fig:results}(a) clearly shows that the SAT-based analysis 
makes significantly more decisions than ACDLP for all the benchmarks. 
The points on the extreme right below the diagonal in
Fig.~\ref{fig:results}(b) show that the number of propagations in the SAT-based 
analysis is maximal for benchmarks that exhibit relational behaviour.  These
benchmarks are solved by the octagon domain in ACDLP.  We see a reduction of at 
least two orders of magnitude in the total number of decisions, propagations 
and conflicts compared to analysis using CBMC.  

Out of 85 benchmarks, SAT-based analysis could prove only 26
benchmarks without any restarts.  The solver was restarted in the other 59 
cases to avoid spending too much time in ``hopeless'' branches.  By contrast, 
ACDLP solved all 85 benchmarks without restarts.  
The runtime comparison between ACDLP and CBMC is shown in 
Figure~\ref{fig:runtimes}.  ACDLP is~1.5X faster than CBMC. 
The superior performance of ACDLP is attributed to the decision heuristics, 
which exploit the high-level structure of the program, combined with the 
precise deduction by multi-way transformer and stronger learnt clauses aided 
by the abstract domains. 
%

\medskip

\noindent \textbf{ACDLP versus Astr{\'e}e}
%
To enable precise analysis with Astr{\'e}e, we manually instrument the
benchmarks with partition directives \texttt{\_\_ASTREE\_partition\_control}
at various control-flow joins.  These directives provide external hints to
Astr{\'e}e to guide its internal trace partitioning domain. 
Figure~\ref{fig:runtimes} demonstrates that Astr{\'e}e is~2X faster than
ACDLP for {37}\% cases (32 out of 85); but the analysis using Astr{\'e}e
shows a high degree of imprecision (marked as timeout in
Figure~\ref{fig:runtimes}).  Astr{\'e}e reported~53 false alarms among~85
benchmarks.  By contrast, the analysis using ACDLP produces correct results
for~81 benchmarks.  ACDLP times out for~4 benchmarks.  Clearly, ACDLP has
higher precision than Astr{\'e}e.  
%
%url{http://www.cprover.org/acdcl/}.
%presented in \rmcmt{Appendix~\ref{appendix:extended_result}.}  


\rmcmt{Our experimental evaluation suggests that ACDLP can be seen as a
technique to improve the efficiency of SAT-based BMC.  Additionally, ACDLP can
also be perceived as an automatic way to improve the precision of conventional
abstract interpretation over non-distributive lattices through automatic
partitioning techniques such as decisions and transformer learning.}


%\section{Detailed Experimental Results}\label{appendix:extended_result}
Table~\ref{detailed_result} gives a detailed comparison between CBMC version
5.5 and ACDLP.  Columns~1--4 in Table~\ref{detailed_result} contain the
name of the tool, the benchmark category, the number of lines of code (LOC),
and the total number of safe and unsafe benchmarks in the respective
categories (labelled as Safe/Unsafe).  The solver statistics ({\em
Decisions, Propagations, Conflicts, Conflict Literals, Restarts}) 
for CBMC and ACDLP are in columns~5--9.
%
%Column~10 reports the total time for verification per category.  

We classify our benchmarks into separate categories. 
We label the benchmarks in bit-vector regression category from SV-COMP'16 
as {\em Bit-vector}, ANSI-C models of hardware circuits auto-generated by v2c 
tool as {\em Verilog-C} and auto-generated Controller code and control-intensive 
benchmarks as {\em Control-Flow} category.  The total number of benchmarks in 
{\em bit-vector} category are 13, {\em Control-Flow} category contains 
55 benchmarks and {\em Verilog-C} category has 17 benchmarks. The timeout for 
our experiments is set to~200 seconds.  All times in Table~\ref{detailed_result} 
and Table~\ref{ai-result} are in seconds. 

The Bit-vector category contains a total of~13 benchmarks, out of which~6
are safe and the remaining~7 are unsafe benchmarks.  The benchmarks in the
control-flow category contains simple bounded loop analysis with relational
properties to more complex controller code containing nested loops with
varying loop bounds.  Out of~55 benchmarks in this category, 35 are safe and
20 are unsafe.  We verified a total of~17 hardware benchmarks, which are
given in Verilog RTL language.  Out of these~17 benchmarks,~10 are safe and
the remaining~7 are unsafe.  The software models (in ANSI-C) for the Verilog
circuits are obtained via a Verilog to C translator tool, {\em v2c}.  These
software models are then fed to CBMC and ACDLP.  The hardware benchmarks
include an implementation of a Instruction buffer logic, FIFO arbiter,
traffic light controller, cache coherence protocol, Dekker's mutual
exclusion algorithm among others.  The largest benchmark is the cache
coherence protocol which consists of~890 LOC and the smallest benchmark is
TicTacToe with~67 LOC.  The software models of these Verilog circuits uses
several complex bit-wise logic to map hardware operations into an equivalent
C syntax.  We emphasize that our implementation can handle bit-wise
operations out-of-the-box.

\begin{table}[!b]
\begin{center}
{
\begin{tabular}{l|l|r|r|r|r|r|r|r}
\hline
           &          &     & Safe/  &           & Propa-  &           & Conflict &          \\
  Verifier & Category & LOC & Unsafe & Decisions & gations & Conflicts & literals & Restarts \\ \hline
  CBMC & \multirow{2}{*}{Bit-vector} & \multirow{2}{*}{501} &
  \multirow{2}{*}{6/7} & 1011 & 1190 & 0 & 0 & 7 \\
  ACDLP & & & & 0 & 44 & 0 & 0 & 0 \\ \hline
  CBMC & \multirow{2}{*}{Control-Flow} & \multirow{2}{*}{1387} & 
  \multirow{2}{*}{35/20} & 29382 & 379727 & 4520 & 37160 & 62 \\ 
  ACDLP & & & & 414 & 6487 & 195 & 180 & 0  \\ \hline
  CBMC & \multirow{2}{*}{Verilog-C} & \multirow{2}{*}{4210} & 
  \multirow{2}{*}{10/7} & 131932 & 322707 & 69 & 349 & 6 \\ 
  ACDLP & & & & 625 & 8196 & 22 & 22 & 0 \\ \hline
\end{tabular}
}
\end{center}
\caption{CBMC versus ACDLP}
\label{detailed_result}
\end{table}

The statistics for ACDLP in Table~\ref{detailed_result} is obtained using an
ordered decision heuristic, multi-way propagation heuristic and a first-UIP
learning heuristic.  Note that the deductions using a multi-way heuristic is
more precise than forward or backward heuristics, but multi-way heuristic
takes longer time to reach the fixed-point.  Furthermore, multi-way
heuristic significantly reduces the total number of decisions, propagations
and learning iterations due to higher precision of the deductions made in
the abstract domain.  Overall, ACDLP reduces the total number of decisions,
propagations, conflicts and restarts by a factor of~20X compared to CBMC.

\begin{table}[t]
\begin{center}
{
\begin{tabular}{l|l|r|r|r}
\hline
  Verifier & Category & \#Proved (safe/unsafe) & \#Inconclusive & \#False Positives \\ \hline
  Astr{\'e}e & \multirow{2}{*}{Bit-vector} & 5/7 & 0 & 1 \\
  ACDLP & & 6/7 & 0 & 0 \\ \hline
  Aste{\'e}e & \multirow{2}{*}{Control-Flow} & 24/9 & 0 & 22 \\
  ACDLP & & 35/17 & 3 & 0 \\ \hline
  Astr{\'e}e & \multirow{2}{*}{Verilog-C} & 2/4 & 0 & 11 \\
  ACDLP & & 9/7 & 1 & 0 \\ \hline
\end{tabular}
}
\end{center}
  \caption{Astr{\'e}e versus ACDLP}
\label{ai-result}
\end{table}

Table~\ref{ai-result} gives a detailed comparison between Astr{\'e}e and
ACDLP.  Columns~1--5 in Table~\ref{ai-result} gives the name of the
tool, the benchmark category, the total number of instances proved safe or
unsafe (labelled as safe/unsafe), the total number of inconclusive
benchmarks and total number of false positives per category.

Table~\ref{ai-result} shows that ACDLP solved twice more benchmarks than
Astr{\'e}e.  The total number of inconclusive results in ACDLP is~4.  The
inconclusive results is because of timeout.  By~contrast, Astr{\'e}e reports
a total of~53 false positives among~85 benchmarks.  Clearly, ACDLP is more
precise than Astr{\'e}e.

\section{Decision Heuristics in ACDLP}~\label{decision}
%
We have implemented several decision heuristics in ACDLP: {\em ordered}, 
{\em longest-range}, {\em random}, and the {\em activity based} 
decision heuristic.  The {\em ordered} decision heuristic 
%creates an ordering among meet irreducibles, 
makes decisions on meet irreducibles that involve conditional 
variables (variables that appear in conditional branches) first 
before choosing meet irreducibles with numerical variables.  
%The ordered heuristic gives an effect of trace partitioning~\cite{toplas07}.
%
The {\em longest-range} heuristic simply keeps track of the bounds
$\numabsval_l,\numabsval_u$ of matching template rows, which are 
%\footnote{These are template rows with row vectors $\vec{c}$, $\vec{c}'$ such that $\vec{c}=-\vec{c}'$.}
row vectors $\vec{c}$, $\vec{c}'$ such that $\vec{c}=-\vec{c}'$.
%\pscmt{[that has become a bit hard to understand since some of the definitions have been removed]} 
$\numabsval_l\leq \vec{c}\vec{x}\leq \numabsval_u$, picks the one with the longest range
$\numabsval_u-\numabsval_l$, and randomly returns the meet irreducible
$\vec{c}\vec{x}\leq
\lfloor\frac{\numabsval_l+\numabsval_u}{2}\rfloor$ or its
complement. This ensures a fairness policy in selecting a variable
since it guarantees that the intervals of meet irreducibles are
uniformly restricted.
%
The {\em random} decision heuristic arbitrarily picks a meet irreducible  
for making decision. 
%
%The {\em relational} decision heuristics is only relevant for relational 
%abstract domains.  
%
The {\em activity based} decision heuristic is inspired by the 
decision heuristic used in the Berkmin SAT solver.  
The activity based heuristic %is currently implemented for interval constraints only.  
%The heuristic 
keeps track of the activity of meet irreducibles that 
participate in conflict clauses.  Based on the most 
active meet irreducible, ranges are split similar to 
the {\em longest-range} heuristic.
%
\section{Decisions, Propagations and Learning in ACDLP}
%
\input{graph2}
%
\paragraph{Propagation Strategy.}
%
Fig.~\ref{prop-dec}(a) presents a comparison between the {\em forward} 
and {\em multi-way} propagation strategy in ACDLP.  The
choice of strategy influences the total number of decisions and clause 
learning iterations.  Hence, the propagation strategy has a
significant influence on the runtime, which can be seen in
Fig.~\ref{prop-dec}(a).  We did not report the performance 
of {\em backward} propagation strategy due to large 
number of timeouts.  Compared to forward propagation, the multi-way
strategy may take more iterations to reach the fixed-point, but it
subsequently reduces the total number of decisions and conflicts to prove the
program.  This is attributed to the higher precision of the meet irreducibles 
inferred by the multi-way strategy, which subsequently aids the decision 
heuristics to make better decisions.  

\paragraph{Decision Heuristics.}
%
Fig.~\ref{prop-dec}(b) shows the performance of different decision
heuristics in ACDLP.  Note that the runtimes for all decision heuristics are
obtained using the multi-way propagation strategy.  The runtimes are very
close, but we can still discern some key characteristics of these
heuristics.  The activity based heuristic performs consistently well for most safe
benchmarks and all bit-vector category benchmarks.  By contrast, the ordered
heuristic performs better for programs with conditional branches since it
prioritises decisions on meet irreducibles that appear in conditionals.  The
runtimes for the random heuristic are marginally higher than the other
two.  This suggests that domain-specific decision heuristics are important
for ACDLP.
%
\Omit{
Whereas activity-based heuristics such as Berkmin heuristic which 
works well in propositional cases performs best for benchmarks 
that encountered the maximum number of conflicts to prove safety, 
thus allowing the heuristics to choose the decision variable among the set of learnt clauses.   
}

\paragraph{Learning.}
%
Learning has a significant influence on the runtime of ACDLP.  We~compare
the UIP-based learning technique with an analysis that performs classical 
DPLL-style analysis.
%chronoligical backtracking without learning.  
The effect of UIP computation allows ACDLP to backtrack non-chronologically 
and guide the model search with a learnt transformer.  But classical 
DPLL-style analysis exhibits case-enumeration behaviour and could not finish 
within the time bound for 20\% of our benchmarks.
%

